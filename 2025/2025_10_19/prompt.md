Jack Stratton, the guy from Vulfpeck, (he plays guitar or sings or something?), he has a really nice 'visualisation' on his youtube channel here: https://www.youtube.com/watch?v=kAT3aVj-A_E
It has the audio of Marvin Gaye's song "Aint no mountain high enough" which features James Jamerson on the bass. 
The visualisation, which Jack calls a "graphic score" show's thin blue-ish line showing the contour of the bassline. At each time a bass note is struck there is a blue dot that is initially filled but when the note is plucked the fill goes away. The radius of the blue dots seems to indicate the duration of the note. There is blue dot of another shade that follows the contour and each time it encounters a filled blue dot of the bassline it takes its radius and fill and continues on gradually getting a bit smaller until it encounters the next dot. This all has the effect of rendering a quite complex bassline in an understandable way even for a watcher who is not a musician. 
I think it that Stratton was moved to create this video as a way of expressing appreciation and awe for the great bass playing of James Jamerson and how he did all of this while really playing the bass with just one finger.
Have I missed anything in my analysis and characterisation of the content of the video and the context surrounding it (e.g. who is James Jamerson and who Jack Stratton is and why does he care about James and his playing?)
Surely the James Jamerson song is subject to copyright restrictions. How does Jack Stratton negotiate this? Like is anyone able to just post the audio of someone elses content on youtube as long as they give appropriate credit? Stratton has over 1 million views on this video - is he recieving any revenue from it?
Ok and my last set of questions...
Let's say I have a song that I love the bassline to... could you show me how I might create a similar visualisation where ideally I end up with something I can render to a video and upload on youtube.
I would love to be able to render something of similar quality, like be able to choose this kind of faded blue that Stratton uses and it almost seems to have a bit of an 'out of focus' feel as if it were rendered on an old computer monitor or oscilloscope.
I imagine the actual "data" for creating such a visualisation would be fairly simple... a sequence of timestamps with say midi pitches and velocity values. This big sequence gets translated somehow into vectors and then there is a visualisation generated. I imagine actually that all this is achievable with svg in a modern browser (is it?). If so, I wonder if you could sketch out how I might achieve something like this (ideally using vue, typescript and primevue for any ui required)... ideally I would like a kind of tool that I can load up an mp3, somehow work on creating the data set (transcribing note by note the bassline pitches and velocity values), as I go check and see that I'm happy with how its looking, and finally when its all done have a json export of the data and somehow be able to run a script that produces an mp4 that can be uploaded to youtube. If needed I'm happy to have a python backend created in flask.
